{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLfinal.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oviyajay/ML-Final-Project/blob/main/MLfinal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOWb6AxezM4z"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os \n",
        "import cv2\n",
        "!pip install tflearn\n",
        "import tflearn \n",
        "from tflearn.layers.conv import conv_2d, max_pool_2d \n",
        "from tflearn.layers.core import input_data, dropout, fully_connected \n",
        "from tflearn.layers.estimator import regression \n",
        "\n",
        "#Members:...\n",
        "#https://blog.paperspace.com/image-captioning-with-ai/\n",
        "#image preprocessing\n",
        "\n",
        "# TEST_W_MASK=\"https://github.com/oviyajay/ML-Final-Project/tree/main/maskdata/maskdata/test/with_mask\"\n",
        "# TEST_WO_MASK=\"https://github.com/oviyajay/ML-Final-Project/tree/main/maskdata/maskdata/test/without_mask\"\n",
        "# TRAIN_W_MASK=\"https://github.com/oviyajay/ML-Final-Project/tree/main/maskdata/maskdata/train/with_mask\"\n",
        "# TRAIN_WO_MASK=\"https://github.com/oviyajay/ML-Final-Project/tree/main/maskdata/maskdata/train/without_mask\"\n",
        "\n",
        "!git clone https://github.com/oviyajay/ML-Final-Project\n",
        "\n",
        "#label the images\n",
        "#create training data and test data \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uI6V8QNzIAT",
        "outputId": "5609c3cb-1d27-4af9-9a9c-2d21758ed4b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Eric \n",
        "train_path = \"/content/ML-Final-Project/maskdata/maskdata/train/\"\n",
        "os.listdir(train_path)\n",
        "\n",
        "test_path = \"/content/ML-Final-Project/maskdata/maskdata/test/\"\n",
        "os.listdir(test_path)\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['with_mask', 'without_mask']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6X4S4x1euWQY"
      },
      "source": [
        "label_names = ['with_mask', 'without_mask']\n",
        "IMG_SIZE = 256\n",
        "\n",
        "def load_data(path):\n",
        "  data = []\n",
        "\n",
        "  for label in label_names:\n",
        "    for filename in os.listdir(os.path.join(path, label)):\n",
        "      img_file = os.path.join(path, label, filename)\n",
        "      # loading the image from the path and then converting them into \n",
        "      # greyscale for easier covnet prob \n",
        "      img = cv2.imread(img_file, cv2.IMREAD_COLOR)\n",
        "\n",
        "      # resizing the image for processing them in the covnet \n",
        "      img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
        "\n",
        "      label_id = label_names.index(label)\n",
        "\n",
        "      # final step-forming the training data list with numpy array of the images \n",
        "      data.append([np.array(img), np.array(label_id)]) \n",
        "\n",
        "      return data\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgefZWnaxlpw"
      },
      "source": [
        "train_data = load_data(train_path)\n",
        "test_data = load_data(test_path)\n",
        "# print(train_data)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOsI47vYx8DQ"
      },
      "source": [
        "# train is a list of [x, y] pairs\n",
        "train_x = [i[0] for i in train_data]  #i[0] is a numpy array that is the size/shape of a single image\n",
        "train_x = np.array(train_x).reshape(-1, IMG_SIZE, IMG_SIZE)  # num_image, width, height, channels\n",
        "train_y = [i[1] for i in train_data]\n",
        "test_x = [i[0] for i in test_data]\n",
        "test_x = np.array(test_x).reshape(-1, IMG_SIZE, IMG_SIZE) \n",
        "test_y = [i[1] for i in test_data]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgiiQ1Z3teiN"
      },
      "source": [
        "#Iant"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQ9LAiGStn4v"
      },
      "source": [
        "#Anindita"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNXpYjbGtp-h"
      },
      "source": [
        "#Oviya\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}