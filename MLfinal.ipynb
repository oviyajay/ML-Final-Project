{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLfinal.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oviyajay/ML-Final-Project/blob/main/MLfinal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOWb6AxezM4z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2f5e13a-e6d5-4544-baed-50848a88f837"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os \n",
        "import cv2\n",
        "\n",
        "#Members:...\n",
        "#https://blog.paperspace.com/image-captioning-with-ai/\n",
        "#image preprocessing\n",
        "\n",
        "\n",
        "\n",
        "!git clone https://github.com/oviyajay/ML-Final-Project\n",
        "\n",
        "#label the images\n",
        "#create training data and test data \n"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'ML-Final-Project' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uI6V8QNzIAT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45d68c6f-910e-4235-9d0b-c6b33f485828"
      },
      "source": [
        " \n",
        "train_path = \"/content/ML-Final-Project/maskdata/maskdata/train/\"\n",
        "os.listdir(train_path)\n",
        "\n",
        "test_path = \"/content/ML-Final-Project/maskdata/maskdata/test/\"\n",
        "os.listdir(test_path)\n",
        "\n"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['with_mask', 'without_mask']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6X4S4x1euWQY"
      },
      "source": [
        "label_names = ['without_mask', 'with_mask']\n",
        "IMG_SIZE = 50\n",
        "LR = 1e-3\n",
        "MODEL_NAME = 'withMaskvsnoMask-{}-{}.model'.format(LR, '6conv-basic')\n",
        "\n",
        "def load_data(path):\n",
        "  data = []\n",
        "\n",
        "  for label in label_names:\n",
        "    for filename in os.listdir(os.path.join(path, label)):\n",
        "    \n",
        "      img_file = os.path.join(path, label, filename)\n",
        "       \n",
        "      img = cv2.imread(img_file, cv2.IMREAD_COLOR)    \n",
        "      \n",
        "\n",
        "      # resizing the image for processing\n",
        "      img = cv2.resize(img, (IMG_SIZE, IMG_SIZE), )\n",
        "      \n",
        "\n",
        "      #withmask: id = 1, withoutmask: id = 0\n",
        "      label_id = label_names.index(label)\n",
        "  \n",
        "\n",
        "      # final step-forming the training data list with numpy array of the images \n",
        "      data.append([np.array(img), np.array(label_id)]) \n",
        "\n",
        "  return data\n",
        "\n"
      ],
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgefZWnaxlpw"
      },
      "source": [
        "train_data = load_data(train_path)\n",
        "test_data = load_data(test_path)\n"
      ],
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOsI47vYx8DQ"
      },
      "source": [
        "train_x = [i[0] for i in train_data]\n",
        "train_x = np.array(train_x, dtype=float).reshape(-1, IMG_SIZE, IMG_SIZE, 3)  # num_image, width, height, channels\n",
        "train_y = [i[1] for i in train_data]\n",
        "train_y = np.array(train_y, dtype=float)\n",
        "test_x = [i[0] for i in test_data]\n",
        "test_x = np.array(test_x).reshape(-1, IMG_SIZE, IMG_SIZE, 3) \n",
        "test_y = [i[1] for i in test_data]\n",
        "test_y = np.array(test_y, dtype=float)\n"
      ],
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNXpYjbGtp-h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dcd4a8f4-97ba-4cf0-ce8c-0ff63ee40ef9"
      },
      "source": [
        "#create our CNN Model\n",
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    #define layers\n",
        "    super(MyModel, self).__init__()\n",
        "    self.conv1 = tf.keras.layers.Conv2D(32, kernel_size=(5,5),activation=tf.nn.relu, input_shape=(IMG_SIZE,IMG_SIZE,3))\n",
        "    self.max1 = tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2))\n",
        "    self.conv2 = tf.keras.layers.Conv2D(64, (5,5), activation = 'relu')\n",
        "    self.max2=tf.keras.layers.MaxPooling2D(pool_size=(2,2))\n",
        "  \n",
        "  def call(self,inputs):\n",
        "    #first convolution layer\n",
        "    convOne = (self.conv1)(inputs)\n",
        "    maxOne = (self.max1)(convOne)\n",
        "    #second convolution layer\n",
        "    convTwo = (self.conv2)(maxOne)\n",
        "    maxTwo = (self.max2)(convTwo)\n",
        "    #flatten the array\n",
        "    flat = tf.keras.layers.Flatten()(maxTwo)\n",
        "    #hidden layer\n",
        "    hiddenLayer = tf.keras.layers.Dense(75, activation = 'relu')(flat) \n",
        "    #output layer\n",
        "    outputLayer = tf.keras.layers.Dense(2, activation ='softmax')(hiddenLayer)\n",
        "\n",
        "\n",
        "\n",
        "    return outputLayer\n",
        "\n",
        "#create an instance of our model\n",
        "model = MyModel()\n",
        "#through keras, the model must be compiled by assiging it a loss function and metrics\n",
        "#since we are using one-hot encoding to classify our images, we will use the loss function \"Categorical Crossentropy\"\n",
        "model.compile(loss='sparse_categorical_crossentropy', metrics=['accuracy'], optimizer='sgd')\n",
        "#next we must fit our data to our model and assign batch_size and number of epochs\n",
        "history = model.fit(train_x,train_y, batch_size= 100, epochs=1000)\n",
        "#_,accuracy = model.evaluate(train_x,train_y)\n",
        "\n",
        "\n"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 616 samples\n",
            "Epoch 1/1000\n",
            "616/616 [==============================] - 2s 4ms/sample - loss: 6057.5486 - acc: 0.4724\n",
            "Epoch 2/1000\n",
            "616/616 [==============================] - 2s 4ms/sample - loss: 0.7096 - acc: 0.4984\n",
            "Epoch 3/1000\n",
            "616/616 [==============================] - 2s 4ms/sample - loss: 0.6925 - acc: 0.5146\n",
            "Epoch 4/1000\n",
            "616/616 [==============================] - 2s 4ms/sample - loss: 0.6812 - acc: 0.5341\n",
            "Epoch 5/1000\n",
            "616/616 [==============================] - 2s 4ms/sample - loss: 0.6792 - acc: 0.5390\n",
            "Epoch 6/1000\n",
            "616/616 [==============================] - 2s 4ms/sample - loss: 0.6807 - acc: 0.5503\n",
            "Epoch 7/1000\n",
            "616/616 [==============================] - 2s 4ms/sample - loss: 0.6658 - acc: 0.5568\n",
            "Epoch 8/1000\n",
            "616/616 [==============================] - 2s 4ms/sample - loss: 0.6527 - acc: 0.5666\n",
            "Epoch 9/1000\n",
            "616/616 [==============================] - 2s 4ms/sample - loss: 0.6407 - acc: 0.5974\n",
            "Epoch 10/1000\n",
            "616/616 [==============================] - 2s 4ms/sample - loss: 0.6291 - acc: 0.5974\n",
            "Epoch 11/1000\n",
            "616/616 [==============================] - 2s 4ms/sample - loss: 0.6244 - acc: 0.6071\n",
            "Epoch 12/1000\n",
            "616/616 [==============================] - 2s 4ms/sample - loss: 0.6045 - acc: 0.6315\n",
            "Epoch 13/1000\n",
            "616/616 [==============================] - 2s 4ms/sample - loss: 0.5945 - acc: 0.6218\n",
            "Epoch 14/1000\n",
            "616/616 [==============================] - 2s 4ms/sample - loss: 0.5704 - acc: 0.6445\n",
            "Epoch 15/1000\n",
            "616/616 [==============================] - 2s 4ms/sample - loss: 0.5669 - acc: 0.6688\n",
            "Epoch 16/1000\n",
            "616/616 [==============================] - 2s 4ms/sample - loss: 0.6037 - acc: 0.6477\n",
            "Epoch 17/1000\n",
            "616/616 [==============================] - 2s 4ms/sample - loss: 0.5406 - acc: 0.7127\n",
            "Epoch 18/1000\n",
            "616/616 [==============================] - 2s 4ms/sample - loss: 0.5340 - acc: 0.7192\n",
            "Epoch 19/1000\n",
            "200/616 [========>.....................] - ETA: 0s - loss: 0.5337 - acc: 0.6800"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-149-da120231e848>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sgd'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m#next we must fit our data to our model and assign batch_size and number of epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;31m#_,accuracy = model.evaluate(train_x,train_y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_v1.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    807\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 809\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    664\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 666\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3824\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3825\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3826\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3827\u001b[0m     output_structure = nest.pack_sequence_as(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rd4pCBlcDdak"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(model.evaluate(train_x,train_y))\n",
        "plt.plot(model.evaluate(test_x,test_y))\n",
        "plt.title('model')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(model.evaluate(train_x,train_y))\n",
        "plt.plot(model.evaluate(test_x,test_y))\n",
        "plt.plot(history.history['acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(model.evaluate(train_x,train_y))\n",
        "plt.plot(model.evaluate(test_x,test_y))\n",
        "plt.plot(history.history['loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}