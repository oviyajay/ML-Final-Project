{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLfinal.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oviyajay/ML-Final-Project/blob/main/MLfinal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOWb6AxezM4z",
        "outputId": "382aee98-bacb-4e20-b2d2-0524a96c1a2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os \n",
        "import cv2\n",
        "!pip install tflearn\n",
        "import tflearn \n",
        "from tflearn.layers.conv import conv_2d, max_pool_2d \n",
        "from tflearn.layers.core import input_data, dropout, fully_connected \n",
        "from tflearn.layers.estimator import regression \n",
        "\n",
        "#Members:...\n",
        "#https://blog.paperspace.com/image-captioning-with-ai/\n",
        "#image preprocessing\n",
        "\n",
        "TEST_W_MASK=\"https://github.com/oviyajay/ML-Final-Project/tree/main/maskdata/maskdata/test/with_mask\"\n",
        "TEST_WO_MASK=\"https://github.com/oviyajay/ML-Final-Project/tree/main/maskdata/maskdata/test/without_mask\"\n",
        "TRAIN_W_MASK=\"https://github.com/oviyajay/ML-Final-Project/tree/main/maskdata/maskdata/train/with_mask\"\n",
        "TRAIN_WO_MASK=\"https://github.com/oviyajay/ML-Final-Project/tree/main/maskdata/maskdata/train/without_mask\"\n",
        "\n",
        "!git clone https://github.com/oviyajay/ML-Final-Project\n",
        "\n",
        "#label the images\n",
        "#create training data and test data \n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tflearn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/3c/0b156d08ef3d4e2a8009ecab2af1ad2e304f6fb99562b6271c68a74a4397/tflearn-0.5.0.tar.gz (107kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 73kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tflearn) (1.18.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tflearn) (1.15.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from tflearn) (7.0.0)\n",
            "Building wheels for collected packages: tflearn\n",
            "  Building wheel for tflearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tflearn: filename=tflearn-0.5.0-cp36-none-any.whl size=127301 sha256=be8d4a7911561493d81a3db8a99920d23011e45f9074421ed7a1f2ac7ac341c0\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/d2/ed/fb9a0d301dd9586c11e9547120278e624227f22fd5f4baf744\n",
            "Successfully built tflearn\n",
            "Installing collected packages: tflearn\n",
            "Successfully installed tflearn-0.5.0\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n",
            "Cloning into 'ML-Final-Project'...\n",
            "remote: Enumerating objects: 889, done.\u001b[K\n",
            "remote: Counting objects: 100% (889/889), done.\u001b[K\n",
            "remote: Compressing objects: 100% (875/875), done.\u001b[K\n",
            "remote: Total 889 (delta 20), reused 826 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (889/889), 25.50 MiB | 25.20 MiB/s, done.\n",
            "Resolving deltas: 100% (20/20), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uI6V8QNzIAT",
        "outputId": "d85aa50f-5377-4050-c102-d308d94d3d65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Eric \n",
        "train_path = \"/content/ML-Final-Project/maskdata/maskdata/train/\"\n",
        "os.listdir(train_path)\n",
        "\n",
        "test_path = \"/content/ML-Final-Project/maskdata/maskdata/test/\"\n",
        "os.listdir(test_path)\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['with_mask', 'without_mask']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6X4S4x1euWQY"
      },
      "source": [
        "label_names = ['with_mask', 'without_mask']\n",
        "IMG_SIZE = 256\n",
        "\n",
        "def load_data(path):\n",
        "  data = []\n",
        "\n",
        "  for label in label_names:\n",
        "    for filename in os.listdir(os.path.join(path, label)):\n",
        "      img_file = os.path.join(path, label, filename)\n",
        "      # loading the image from the path and then converting them into \n",
        "      # greyscale for easier covnet prob \n",
        "      img = cv2.imread(img_file, cv2.IMREAD_COLOR)\n",
        "\n",
        "      # resizing the image for processing them in the covnet \n",
        "      img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
        "\n",
        "      label_id = label_names.index(label)\n",
        "\n",
        "      # final step-forming the training data list with numpy array of the images \n",
        "      data.append([np.array(img), np.array(label_id)]) \n",
        "\n",
        "      return data\n",
        "\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgefZWnaxlpw",
        "outputId": "a8d7ce58-0e6c-45d5-be0c-18c90f28a1e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_data = load_data(train_path)\n",
        "test_data = load_data(test_path)\n",
        "print(train_data)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[array([[[ 13,   5,  13],\n",
            "        [ 26,  18,  28],\n",
            "        [ 28,  23,  32],\n",
            "        ...,\n",
            "        [ 14,  19,  32],\n",
            "        [ 13,  19,  32],\n",
            "        [  3,   5,  15]],\n",
            "\n",
            "       [[ 19,  12,  22],\n",
            "        [ 42,  38,  47],\n",
            "        [ 53,  52,  63],\n",
            "        ...,\n",
            "        [ 44,  53,  66],\n",
            "        [ 36,  43,  56],\n",
            "        [  9,  13,  25]],\n",
            "\n",
            "       [[ 10,  11,  21],\n",
            "        [ 37,  40,  50],\n",
            "        [ 51,  58,  68],\n",
            "        ...,\n",
            "        [ 44,  52,  66],\n",
            "        [ 39,  47,  60],\n",
            "        [ 12,  17,  28]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[  6,  19,  51],\n",
            "        [ 80, 106, 140],\n",
            "        [100, 130, 166],\n",
            "        ...,\n",
            "        [ 84, 110, 163],\n",
            "        [ 66,  84, 134],\n",
            "        [  8,  20,  68]],\n",
            "\n",
            "       [[ 16,  36,  63],\n",
            "        [ 89, 111, 139],\n",
            "        [109, 132, 165],\n",
            "        ...,\n",
            "        [ 87, 108, 160],\n",
            "        [ 68,  84, 133],\n",
            "        [ 21,  30,  77]],\n",
            "\n",
            "       [[  3,  12,  32],\n",
            "        [ 34,  53,  76],\n",
            "        [ 32,  51,  79],\n",
            "        ...,\n",
            "        [ 24,  40,  90],\n",
            "        [ 22,  33,  82],\n",
            "        [  3,   6,  49]]], dtype=uint8), array(0)]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOsI47vYx8DQ"
      },
      "source": [
        "# train is a list of [x, y] pairs\n",
        "train_x = [i[0] for i in train_data]  #i[0] is a numpy array that is the size/shape of a single image\n",
        "train_x = np.array(train_x).reshape(-1, IMG_SIZE, IMG_SIZE)  # num_image, width, height, channels\n",
        "train_y = [i[1] for i in train_data]\n",
        "test_x = [i[0] for i in test_data]\n",
        "test_x = np.array(test_x).reshape(-1, IMG_SIZE, IMG_SIZE) \n",
        "test_y = [i[1] for i in test_data]"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgiiQ1Z3teiN"
      },
      "source": [
        "#Iant"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQ9LAiGStn4v"
      },
      "source": [
        "#Anindita"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNXpYjbGtp-h"
      },
      "source": [
        "#Oviya\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}