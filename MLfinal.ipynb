{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLfinal.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oviyajay/ML-Final-Project/blob/main/MLfinal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOWb6AxezM4z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69963a6e-c85f-4bdb-faf9-3976dffb00dc"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os \n",
        "import cv2\n",
        "!pip install tflearn\n",
        "import tflearn \n",
        "from tflearn.layers.conv import conv_2d, max_pool_2d \n",
        "from tflearn.layers.core import input_data, dropout, fully_connected \n",
        "from tflearn.layers.estimator import regression \n",
        "\n",
        "#Members:...\n",
        "#https://blog.paperspace.com/image-captioning-with-ai/\n",
        "#image preprocessing\n",
        "\n",
        "# TEST_W_MASK=\"https://github.com/oviyajay/ML-Final-Project/tree/main/maskdata/maskdata/test/with_mask\"\n",
        "# TEST_WO_MASK=\"https://github.com/oviyajay/ML-Final-Project/tree/main/maskdata/maskdata/test/without_mask\"\n",
        "# TRAIN_W_MASK=\"https://github.com/oviyajay/ML-Final-Project/tree/main/maskdata/maskdata/train/with_mask\"\n",
        "# TRAIN_WO_MASK=\"https://github.com/oviyajay/ML-Final-Project/tree/main/maskdata/maskdata/train/without_mask\"\n",
        "\n",
        "!git clone https://github.com/oviyajay/ML-Final-Project\n",
        "\n",
        "#label the images\n",
        "#create training data and test data \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tflearn in /usr/local/lib/python3.6/dist-packages (0.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tflearn) (1.18.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from tflearn) (7.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tflearn) (1.15.0)\n",
            "fatal: destination path 'ML-Final-Project' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uI6V8QNzIAT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43ee92e2-fd95-46e7-cb2a-8c4e124eb9da"
      },
      "source": [
        "#Eric \n",
        "train_path = \"/content/ML-Final-Project/maskdata/maskdata/train/\"\n",
        "os.listdir(train_path)\n",
        "\n",
        "test_path = \"/content/ML-Final-Project/maskdata/maskdata/test/\"\n",
        "os.listdir(test_path)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['without_mask', 'with_mask']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6X4S4x1euWQY"
      },
      "source": [
        "label_names = ['with_mask', 'without_mask']\n",
        "IMG_SIZE = 256\n",
        "LR = 1e-3\n",
        "MODEL_NAME = 'withMaskvsnoMask-{}-{}.model'.format(LR, '6conv-basic')\n",
        "\n",
        "def load_data(path):\n",
        "  data = []\n",
        "\n",
        "  for label in label_names:\n",
        "    for filename in os.listdir(os.path.join(path, label)):\n",
        "      img_file = os.path.join(path, label, filename)\n",
        "      # loading the image from the path and then converting them into \n",
        "      # greyscale for easier covnet prob \n",
        "      img = cv2.imread(img_file, cv2.IMREAD_COLOR)\n",
        "\n",
        "      # resizing the image for processing them in the covnet \n",
        "      img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
        "\n",
        "      label_id = label_names.index(label)\n",
        "\n",
        "      # final step-forming the training data list with numpy array of the images \n",
        "      data.append([np.array(img), np.array(label_id)]) \n",
        "\n",
        "      return data\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgefZWnaxlpw"
      },
      "source": [
        "train_data = load_data(train_path)\n",
        "test_data = load_data(test_path)\n",
        "# print(train_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOsI47vYx8DQ"
      },
      "source": [
        "# train is a list of [x, y] pairs\n",
        "train_x = [i[0] for i in train_data]  #i[0] is a numpy array that is the size/shape of a single image\n",
        "train_x = np.array(train_x).reshape(-1, IMG_SIZE, IMG_SIZE)  # num_image, width, height, channels\n",
        "train_y = [i[1] for i in train_data]\n",
        "test_x = [i[0] for i in test_data]\n",
        "test_x = np.array(test_x).reshape(-1, IMG_SIZE, IMG_SIZE) \n",
        "test_y = [i[1] for i in test_data]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgiiQ1Z3teiN"
      },
      "source": [
        "#Iant\n",
        "#tf.reset_default_graph() \n",
        "cnn = input_data(shape =[None, IMG_SIZE, IMG_SIZE, 1], name ='input') \n",
        "\n",
        "#convolution and pooling operations\n",
        "#as for the arguments, (convolutional network, numbers of channels, filter size(if one number 'x' is passed, then both dimensions are 'x' ), activation function used)\n",
        "#in our case, we're starting with 16 channels, gradually working up to 128. By convention, the number of channels gradually increase or stay the same as it works its way further into the CNN\n",
        "#filter size changed from 5x5 to 3x3\n",
        "\n",
        "cnn = conv_2d(cnn, 16, 3, activation ='relu') \n",
        "cnn = max_pool_2d(cnn, 3) \n",
        "\n",
        "cnn = conv_2d(cnn, 32, 3, activation ='relu') \n",
        "cnn = max_pool_2d(cnn, 3) \n",
        "  \n",
        "cnn = conv_2d(cnn, 64, 3, activation ='relu') \n",
        "cnn = max_pool_2d(cnn, 3) \n",
        "  \n",
        "cnn = conv_2d(cnn, 128, 3, activation ='relu') \n",
        "cnn = max_pool_2d(cnn, 3) \n",
        "  \n",
        "cnn = fully_connected(cnn, 1024, activation ='relu') \n",
        "cnn = dropout(cnn, 0.8) \n",
        "  \n",
        "cnn = fully_connected(cnn, 2, activation ='softmax') \n",
        "cnn = regression(cnn, optimizer ='adam', learning_rate = LR, \n",
        "      loss ='categorical_crossentropy', name ='targets') \n",
        "  \n",
        "model = tflearn.DNN(cnn, tensorboard_dir ='log') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQ9LAiGStn4v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "c107090f-a151-4df6-db50-bfb85b18989d"
      },
      "source": [
        "#Anindita\n",
        "#assigning the labels for both the test and train data\n",
        "x = np.array( [i[0] for i in train_data ])\n",
        "y = np.array([i[1] for i in train_data])\n",
        "\n",
        "test_x = np.array([i[0] for i in test_data])\n",
        "test_y = np.array([i[1] for i in test_data])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-fc7c482c967b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtest_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'input'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'targets'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'input'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest_x\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'targets'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msnapshot_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_metric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMODEL_NAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_NAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNXpYjbGtp-h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9c78e24-3516-4301-be01-1337e48d3bc6"
      },
      "source": [
        "#Oviya\n",
        "model.fit({'input': train_x}, {'targets': train_y}, n_epoch=10, validation_set=({'input': test_x}, {'targets': test_y}),snapshot_step = 500, show_metric=True,run_id = MODEL_NAME )\n",
        "model.save(MODEL_NAME)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------------------------------\n",
            "Run id: withMaskvsnoMask-0.001-6conv-basic.model\n",
            "Log directory: log/\n",
            "---------------------------------\n",
            "Training samples: 6\n",
            "Validation samples: 2\n",
            "--\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Exception in thread Thread-13:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 864, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tflearn/data_flow.py\", line 187, in fill_feed_dict_queue\n",
            "    data = self.retrieve_data(batch_ids)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tflearn/data_flow.py\", line 222, in retrieve_data\n",
            "    utils.slice_array(self.feed_dict[key], batch_ids)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tflearn/utils.py\", line 204, in slice_array\n",
            "    return X[start]\n",
            "IndexError: index 1 is out of bounds for axis 0 with size 1\n",
            "\n",
            "Exception in thread Thread-15:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 864, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tflearn/data_flow.py\", line 187, in fill_feed_dict_queue\n",
            "    data = self.retrieve_data(batch_ids)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tflearn/data_flow.py\", line 222, in retrieve_data\n",
            "    utils.slice_array(self.feed_dict[key], batch_ids)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tflearn/utils.py\", line 204, in slice_array\n",
            "    return X[start]\n",
            "IndexError: index 2 is out of bounds for axis 0 with size 1\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}