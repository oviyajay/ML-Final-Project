{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLfinal.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oviyajay/ML-Final-Project/blob/main/MLfinal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOWb6AxezM4z",
        "outputId": "382aee98-bacb-4e20-b2d2-0524a96c1a2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os \n",
        "import cv2\n",
        "!pip install tflearn\n",
        "import tflearn \n",
        "from tflearn.layers.conv import conv_2d, max_pool_2d \n",
        "from tflearn.layers.core import input_data, dropout, fully_connected \n",
        "from tflearn.layers.estimator import regression \n",
        "\n",
        "#Members:...\n",
        "#https://blog.paperspace.com/image-captioning-with-ai/\n",
        "#image preprocessing\n",
        "\n",
        "TEST_W_MASK=\"https://github.com/oviyajay/ML-Final-Project/tree/main/maskdata/maskdata/test/with_mask\"\n",
        "TEST_WO_MASK=\"https://github.com/oviyajay/ML-Final-Project/tree/main/maskdata/maskdata/test/without_mask\"\n",
        "TRAIN_W_MASK=\"https://github.com/oviyajay/ML-Final-Project/tree/main/maskdata/maskdata/train/with_mask\"\n",
        "TRAIN_WO_MASK=\"https://github.com/oviyajay/ML-Final-Project/tree/main/maskdata/maskdata/train/without_mask\"\n",
        "\n",
        "!git clone https://github.com/oviyajay/ML-Final-Project\n",
        "\n",
        "#label the images\n",
        "#create training data and test data \n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tflearn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/3c/0b156d08ef3d4e2a8009ecab2af1ad2e304f6fb99562b6271c68a74a4397/tflearn-0.5.0.tar.gz (107kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 73kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tflearn) (1.18.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tflearn) (1.15.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from tflearn) (7.0.0)\n",
            "Building wheels for collected packages: tflearn\n",
            "  Building wheel for tflearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tflearn: filename=tflearn-0.5.0-cp36-none-any.whl size=127301 sha256=be8d4a7911561493d81a3db8a99920d23011e45f9074421ed7a1f2ac7ac341c0\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/d2/ed/fb9a0d301dd9586c11e9547120278e624227f22fd5f4baf744\n",
            "Successfully built tflearn\n",
            "Installing collected packages: tflearn\n",
            "Successfully installed tflearn-0.5.0\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n",
            "Cloning into 'ML-Final-Project'...\n",
            "remote: Enumerating objects: 889, done.\u001b[K\n",
            "remote: Counting objects: 100% (889/889), done.\u001b[K\n",
            "remote: Compressing objects: 100% (875/875), done.\u001b[K\n",
            "remote: Total 889 (delta 20), reused 826 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (889/889), 25.50 MiB | 25.20 MiB/s, done.\n",
            "Resolving deltas: 100% (20/20), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uI6V8QNzIAT",
        "outputId": "d85aa50f-5377-4050-c102-d308d94d3d65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Eric \n",
        "train_path = \"/content/ML-Final-Project/maskdata/maskdata/train/\"\n",
        "os.listdir(train_path)\n",
        "\n",
        "test_path = \"/content/ML-Final-Project/maskdata/maskdata/test/\"\n",
        "os.listdir(test_path)\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['with_mask', 'without_mask']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6X4S4x1euWQY"
      },
      "source": [
        "label_names = ['with_mask', 'without_mask']\n",
        "IMG_SIZE = 256\n",
        "\n",
        "def load_data(path):\n",
        "  data = []\n",
        "\n",
        "  for label in label_names:\n",
        "    for filename in os.listdir(os.path.join(path, label)):\n",
        "      img_file = os.path.join(path, label, filename)\n",
        "      # loading the image from the path and then converting them into \n",
        "      # greyscale for easier covnet prob \n",
        "      img = cv2.imread(img_file, cv2.IMREAD_COLOR) # Grayscale => number_of_channels=1, RGB => number_of_channels=3\n",
        "\n",
        "      # resizing the image for processing them in the covnet \n",
        "      img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
        "\n",
        "      label_id = label_names.index(label)\n",
        "\n",
        "      # final step-forming the training data list with numpy array of the images \n",
        "      data.append([np.array(img), np.array(label_id)]) \n",
        "\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgefZWnaxlpw"
      },
      "source": [
        "train_data = load_data(train_path)\n",
        "test_data = load_data(test_path)\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOsI47vYx8DQ",
        "outputId": "b2252b5e-160f-473f-9d8e-1e552289817f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "source": [
        "# train is a list of [x, y] pairs\n",
        "train_x = [i[0] for i in train_data]  #i[0] is a numpy array that is the size/shape of a single image\n",
        "train_x = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE)  # num_image, width, height, channels\n",
        "train_y = [i[1] for i in train_data]\n",
        "test_x = [i[0] for i in test_data]\n",
        "test_x = np.array(test_x).reshape(-1, IMG_SIZE, IMG_SIZE) \n",
        "test_y = [i[1] for i in test_data]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-327af89cf3dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# train is a list of [x, y] pairs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m#i[0] is a numpy array that is the size/shape of a single image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtrain_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMG_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMG_SIZE\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# num_image, width, height, channels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgiiQ1Z3teiN"
      },
      "source": [
        "#Iant"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQ9LAiGStn4v"
      },
      "source": [
        "#Anindita"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNXpYjbGtp-h"
      },
      "source": [
        "#Oviya\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}