{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLfinal.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oviyajay/ML-Final-Project/blob/main/MLfinal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOWb6AxezM4z",
        "outputId": "5d318a0d-d4ec-429d-e844-c105d004149a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os \n",
        "import cv2\n",
        "!pip install tflearn\n",
        "import tflearn \n",
        "from tflearn.layers.conv import conv_2d, max_pool_2d \n",
        "from tflearn.layers.core import input_data, dropout, fully_connected \n",
        "from tflearn.layers.estimator import regression \n",
        "\n",
        "#Members:...\n",
        "#https://blog.paperspace.com/image-captioning-with-ai/\n",
        "#image preprocessing\n",
        "\n",
        "# TEST_W_MASK=\"https://github.com/oviyajay/ML-Final-Project/tree/main/maskdata/maskdata/test/with_mask\"\n",
        "# TEST_WO_MASK=\"https://github.com/oviyajay/ML-Final-Project/tree/main/maskdata/maskdata/test/without_mask\"\n",
        "# TRAIN_W_MASK=\"https://github.com/oviyajay/ML-Final-Project/tree/main/maskdata/maskdata/train/with_mask\"\n",
        "# TRAIN_WO_MASK=\"https://github.com/oviyajay/ML-Final-Project/tree/main/maskdata/maskdata/train/without_mask\"\n",
        "\n",
        "!git clone https://github.com/oviyajay/ML-Final-Project\n",
        "\n",
        "#label the images\n",
        "#create training data and test data \n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tflearn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/3c/0b156d08ef3d4e2a8009ecab2af1ad2e304f6fb99562b6271c68a74a4397/tflearn-0.5.0.tar.gz (107kB)\n",
            "\r\u001b[K     |███                             | 10kB 17.2MB/s eta 0:00:01\r\u001b[K     |██████                          | 20kB 20.1MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 30kB 11.2MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 40kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 51kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 61kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 71kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 81kB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 92kB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 102kB 6.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 112kB 6.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tflearn) (1.18.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tflearn) (1.15.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from tflearn) (7.0.0)\n",
            "Building wheels for collected packages: tflearn\n",
            "  Building wheel for tflearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tflearn: filename=tflearn-0.5.0-cp36-none-any.whl size=127301 sha256=01abab863367a641214270b0d29b4b60fa98754d727c569d7a37ff233b4d3f00\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/d2/ed/fb9a0d301dd9586c11e9547120278e624227f22fd5f4baf744\n",
            "Successfully built tflearn\n",
            "Installing collected packages: tflearn\n",
            "Successfully installed tflearn-0.5.0\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n",
            "Cloning into 'ML-Final-Project'...\n",
            "remote: Enumerating objects: 901, done.\u001b[K\n",
            "remote: Counting objects: 100% (901/901), done.\u001b[K\n",
            "remote: Compressing objects: 100% (887/887), done.\u001b[K\n",
            "remote: Total 901 (delta 24), reused 826 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (901/901), 25.50 MiB | 33.31 MiB/s, done.\n",
            "Resolving deltas: 100% (24/24), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uI6V8QNzIAT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0449fbc8-f40f-403e-fd8c-c9578282ed04"
      },
      "source": [
        "#Eric \n",
        "train_path = \"/content/ML-Final-Project/maskdata/maskdata/train/\"\n",
        "os.listdir(train_path)\n",
        "\n",
        "test_path = \"/content/ML-Final-Project/maskdata/maskdata/test/\"\n",
        "os.listdir(test_path)\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['with_mask', 'without_mask']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6X4S4x1euWQY"
      },
      "source": [
        "label_names = ['with_mask', 'without_mask']\n",
        "IMG_SIZE = 256\n",
        "\n",
        "def load_data(path):\n",
        "  data = []\n",
        "\n",
        "  for label in label_names:\n",
        "    for filename in os.listdir(os.path.join(path, label)):\n",
        "      img_file = os.path.join(path, label, filename)\n",
        "      # loading the image from the path and then converting them into \n",
        "      # greyscale for easier covnet prob \n",
        "      img = cv2.imread(img_file, cv2.IMREAD_COLOR)\n",
        "\n",
        "      # resizing the image for processing them in the covnet \n",
        "      img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
        "\n",
        "      label_id = label_names.index(label)\n",
        "\n",
        "      # final step-forming the training data list with numpy array of the images \n",
        "      data.append([np.array(img), np.array(label_id)]) \n",
        "\n",
        "      return data\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgefZWnaxlpw"
      },
      "source": [
        "train_data = load_data(train_path)\n",
        "test_data = load_data(test_path)\n",
        "# print(train_data)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOsI47vYx8DQ"
      },
      "source": [
        "# train is a list of [x, y] pairs\n",
        "train_x = [i[0] for i in train_data]  #i[0] is a numpy array that is the size/shape of a single image\n",
        "train_x = np.array(train_x).reshape(-1, IMG_SIZE, IMG_SIZE)  # num_image, width, height, channels\n",
        "train_y = [i[1] for i in train_data]\n",
        "test_x = [i[0] for i in test_data]\n",
        "test_x = np.array(test_x).reshape(-1, IMG_SIZE, IMG_SIZE) \n",
        "test_y = [i[1] for i in test_data]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgiiQ1Z3teiN",
        "outputId": "aec33894-9b63-48fe-953d-c65cc8c6a582",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        }
      },
      "source": [
        "#Iant\n",
        "#tf.reset_default_graph() \n",
        "cnn = input_data(shape =[None, IMG_SIZE, IMG_SIZE, 1], name ='input') \n",
        "\n",
        "#convolution and pooling operations\n",
        "#as for the arguments, (convolutional network, numbers of channels, filter size(if one number 'x' is passed, then both dimensions are 'x' ), activation function used)\n",
        "#in our case, we're starting with 16 channels, gradually working up to 128. By convention, the number of channels gradually increase or stay the same as it works its way further into the CNN\n",
        "#filter size changed from 5x5 to 3x3\n",
        "\n",
        "cnn = conv_2d(cnn, 16, 3, activation ='relu') \n",
        "cnn = max_pool_2d(cnn, 3) \n",
        "\n",
        "cnn = conv_2d(cnn, 32, 3, activation ='relu') \n",
        "cnn = max_pool_2d(cnn, 3) \n",
        "  \n",
        "cnn = conv_2d(cnn, 64, 3, activation ='relu') \n",
        "cnn = max_pool_2d(cnn, 3) \n",
        "  \n",
        "cnn = conv_2d(cnn, 128, 3, activation ='relu') \n",
        "cnn = max_pool_2d(cnn, 3) \n",
        "  \n",
        "cnn = fully_connected(cnn, 1024, activation ='relu') \n",
        "cnn = dropout(cnn, 0.8) \n",
        "  \n",
        "cnn = fully_connected(cnn, 2, activation ='softmax') \n",
        "cnn = regression(cnn, optimizer ='adam', learning_rate = learning_rate, \n",
        "      loss ='categorical_crossentropy', name ='targets') \n",
        "  \n",
        "model = tflearn.DNN(cnn, tensorboard_dir ='log') "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tflearn/initializations.py:110: calling UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py:507: UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tflearn/initializations.py:165: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-3b0b18d6b8e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mcnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfully_connected\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m cnn = regression(cnn, optimizer ='adam', learning_rate = LR, \n\u001b[0m\u001b[1;32m     27\u001b[0m       loss ='categorical_crossentropy', name ='targets') \n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'LR' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQ9LAiGStn4v"
      },
      "source": [
        "#Anindita"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNXpYjbGtp-h"
      },
      "source": [
        "#Oviya\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}